{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artists\n",
    "These are the artists preselected for this music festival. We will collect data for all of them to determine the best candidate for each stage.\n",
    "\n",
    "## Rage Stage (rap stage)\n",
    "- Lil uzi vert\n",
    "- Chance the Rapper\n",
    "- Trippie Redd\n",
    "- YBN Cordae\n",
    "- Kanye West\n",
    "\n",
    "## Unwind (acoustic/soft rock stage)\n",
    "- Jack Johnson\n",
    "- John Mayer\n",
    "- The Head and the Heart\n",
    "- Khrubangbin\n",
    "- Rex Orange County\n",
    "\n",
    "## The Haus (dance stage)\n",
    "- Ricky Retro\n",
    "- Flume\n",
    "- Louis the Child\n",
    "- Hippie Sabatoge\n",
    "- Fisher\n",
    "\n",
    "## Hick Stage (country stage)\n",
    "- Jake Owen\n",
    "- Kenny Chesney\n",
    "- Thomas rhett\n",
    "- Luke Bryan\n",
    "- Jon Pardi\n",
    "\n",
    "## Mane Stage (most popular)\n",
    "- Justin Beiber\n",
    "- Ed Sheeran\n",
    "- Taylor Swift\n",
    "- Lorde\n",
    "- Frank Ocean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Authorization Token\n",
    "Link for access token used for every endpoint : https://developer.spotify.com/console/get-search-item/\n",
    "\n",
    "*tokens expire every hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter access token \n",
    "token = \"BQCe4CeGomwTTg6H0BScauDYcyx4oUfdYIfEiZ813xhrbUl-m02baSx72iGhF_uLC_5eaRWr0W6OZM0zBUjbrOTU2rTK2lf8J9WLAef5_xXhL10w-xB8zJybKK6uLOTbuFH8iCpjJf-aoLyLfNX0p_XFQ0zCfrQWkJ7x7ift3xFX6Fxbr9plIeoc6dzofWIMmyfV_NiFcD5FgGKSGj0wRwKiGf6lfuF4F_drQNbL_LLduzjGi6CT2oz-pzWZQPLllkL98DpOWGP_qYM\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Artist Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist(token,artist):\n",
    "    \"\"\"\n",
    "    The following function, takes advantage of Spotify's search endpoint to return an artist's ID\n",
    "    based off of their name. \n",
    "    Parameters\n",
    "    -----------\n",
    "    Token- temporary authorization token generated by spotify\n",
    "    artist - name of the desired artist to get info for\n",
    "    -----------\n",
    "    Link for access token: https://developer.spotify.com/console/get-search-item/\n",
    "    \"\"\"\n",
    "    artist_spotify_url = \"https://api.spotify.com/v1/search\"\n",
    "    api_token = token #must get token from spotify to access data\n",
    "    artist_headers = {\"Authorization\" : \"Bearer %s\"%api_token, \"Content-Type\": \"application/json\"} \n",
    "    artist_params = {\"type\": \"artist\", \"q\":artist}\n",
    "    artist_request = requests.get(artist_spotify_url, params=artist_params, headers=artist_headers)\n",
    "    loaded_data = json.loads(artist_request.text) #get raw data in json format\n",
    "    follower_count = [] #store follower counts for search results\n",
    "    artist_dict = {}# store follower count as key and artist ID and name's as value \n",
    "    for i in range(len(json.loads(artist_request.text)[\"artists\"][\"items\"])):\n",
    "        ID = (loaded_data[\"artists\"][\"items\"][i][\"id\"])#artist's unique id\n",
    "        name = (loaded_data[\"artists\"][\"items\"][i][\"name\"])\n",
    "        followers = (loaded_data[\"artists\"][\"items\"][i][\"followers\"]['total'])\n",
    "        popularity = (loaded_data[\"artists\"][\"items\"][i][\"popularity\"])\n",
    "        artist_dict[followers] = [ID,name,popularity,followers]\n",
    "        follower_count.append(followers)\n",
    "        true_artist = max(follower_count)\n",
    "        true_artist_dict = artist_dict[true_artist]\n",
    "        return true_artist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate artist_table using search\n",
    "artists = [\"Lil uzi vert\", \"Chance the Rapper\", \"Trippie Redd\", \"YBN Cordae\", \"Kanye West\", \"Jack Johnson\", \"John Mayer\",\n",
    "           \"The Head and the Heart\", \"Khrubangbin\", \"Rex Orange County\", \"Ricky Retro\", \"Flume\", \"Louis the Child\", \n",
    "           \"Hippie Sabatoge\", \"Fisher\", \"Jake Owen\", \"Kenny Chesney\", \"Thomas rhett\", \"Luke Bryan\", \"Jon Pardi\",\n",
    "           \"Justin Beiber\", \"Ed Sheeran\", \"Taylor Swift\", \"Lorde\", \"Frank Ocean\"\n",
    "          ]\n",
    "#create dictionary for dataframe\n",
    "artists_dict = {\n",
    "    \"artist_id\" : [],\n",
    "    \"name\" : [],\n",
    "    \"popularity\" : [],\n",
    "    \"followers\" : []\n",
    "    }\n",
    "#iterate through artists to populate dictionary with appropriate data\n",
    "for x in artists:\n",
    "    artists_dict[\"name\"].append(x) #pass in name from list\n",
    "    artists_dict[\"artist_id\"].append(get_artist(token,x)[0])\n",
    "    artists_dict[\"popularity\"].append(get_artist(token,x)[2])\n",
    "    artists_dict[\"followers\"].append(get_artist(token,x)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign artists to a dataframe\n",
    "artists = pd.DataFrame(artists_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to csv\n",
    "artists.to_csv(\"artist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Album Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_albums(album_data,passed_dict):\n",
    "    \"\"\"\n",
    "    This is a helper function for the add_all_albums function. It takes in a request loaded with json and appends it to a dictionary\n",
    "    passed in. There is no output. \n",
    "    \n",
    "    parameters\n",
    "    --------\n",
    "    album_data: json loaded request with album data using the spotify api\n",
    "    passed_dict: the dictionary this information is being appended to\n",
    "    \"\"\"\n",
    "    for i in range(len(album_data['items'])):\n",
    "        name = album_data['items'][i]['name']\n",
    "        passed_dict['name'].append(name)\n",
    "        ID = album_data['items'][i]['id']\n",
    "        passed_dict['album_id'].append(ID)\n",
    "        total_tracks = album_data['items'][i]['total_tracks']\n",
    "        passed_dict['total_tracks'].append(total_tracks)\n",
    "        release_date = album_data['items'][i]['release_date']\n",
    "        passed_dict['release_date'].append(release_date)\n",
    "        album_type = album_data['items'][i]['album_type']\n",
    "        passed_dict['album_type'].append(album_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_all_albums (artist_id, album_type):\n",
    "    \"\"\"\n",
    "    This function takes in an artist id and album type and returns album data for that artist using the spotify API.\n",
    "    The datframe will output album ID, number of tracks, duration, release date and album type (single or album).\n",
    "    For more info about code behind output, see add_albums helper function. Because the Spotify only returns 20 results\n",
    "    by default, the function has a loop to override this limit and get all of the albums an artist has.\n",
    "    \n",
    "    parameters\n",
    "    --------\n",
    "    artist_id: spotify artist id \n",
    "    album_type: either single or album \n",
    "    \"\"\"\n",
    "    album_spotify_url = \"https://api.spotify.com/v1/artists/{}/albums\".format(artist_id)#spotify endpoint to get an artist's albums\n",
    "    api_token = token #must get token from spotify to access data\n",
    "    headers = {\"Authorization\" : \"Bearer %s\"%api_token, \"Content-Type\": \"application/json\"} \n",
    "    offset = 0 #indicates starting point for album's, add 20 every iteration until all albums are collected\n",
    "    params = {\"include_groups\":  album_type, \"offset\": str(offset)} #keep offset dynamic to get more than 20 albums\n",
    "    request_og = requests.get(album_spotify_url, headers=headers, params=params)\n",
    "    loaded_data_og = json.loads(request_og.text) #get raw data in json format\n",
    "    #create dictionary for dataframe\n",
    "    albums_dict ={\n",
    "        \"album_id\":[],\n",
    "        \"name\":[],\n",
    "        \"total_tracks\":[],\n",
    "        \"release_date\":[],\n",
    "        \"album_type\":[]\n",
    "    }\n",
    "    add_albums(loaded_data_og, albums_dict) # propogate the dict with the first 20 entries\n",
    "    #If an artist has more than 20 albums, get them\n",
    "    while len(albums_dict[\"album_id\"]) < loaded_data_og['total']:\n",
    "         #repeat request using updated starting point\n",
    "        offset +=20\n",
    "        params[\"offset\"] = str(offset)\n",
    "        request = requests.get(album_spotify_url, headers=headers, params=params)\n",
    "        loaded_data = json.loads(request.text)\n",
    "        add_albums(loaded_data, albums_dict)\n",
    "    output = pd.DataFrame(albums_dict) #read dict to a dataframe\n",
    "    output[\"artist_id\"] = artist_id#add artist id as foreign key to artist table\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "artist_ids = [x for x in artists['id']]#get artist id from artist table into a list\n",
    "album_df = pd.DataFrame()# create an empty dataframe to store albums\n",
    "for x in artist_ids:\n",
    "    #iterate through each artist and add all of their albums , first finding singles, then finding albums\n",
    "    album1_df = add_all_albums(x, \"single\")\n",
    "    album_df = album_df.append(album1_df)\n",
    "    album2_df = add_all_albums(x,\"album\")\n",
    "    album_df = album_df.append(album2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** In the above table, I chose only to show singles and albums, not tracks featured on, however, that data could easily be collected if one desired (ex. \"appears_on\") See https://developer.spotify.com/documentation/web-api/reference/artists/get-artists-albums/ for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_album_popularity(album_id):\n",
    "    \"\"\"\n",
    "    Because the album object returned in the above endpoint isn't the full object, we must pass each album in the \n",
    "    database into the \"get album\" endpoint in order to get popularity for an album. \n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    album_id-spotify unique identifier for each album\n",
    "    \"\"\"\n",
    "    album_spotify_url = \"https://api.spotify.com/v1/albums/{}\".format(album_id)\n",
    "    api_token = token #must get token from spotify to access data\n",
    "    headers = {\"Authorization\" : \"Bearer %s\"%api_token, \"Content-Type\": \"application/json\"} \n",
    "    request = requests.get(album_spotify_url, headers=headers)\n",
    "    loaded_test_data = json.loads(request.text) #get raw data in json format\n",
    "    return loaded_test_data['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_ids = [album_id for album_id in album_df[\"album_id\"] ] #get album ids for each record in the album table into a list\n",
    "#add popularity to each id\n",
    "for album_id in album_ids:\n",
    "    album_df.loc[album_df.album_id == album_id, 'popularity'] = get_album_popularity(album_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_df.to_csv(\"album.csv\", index = False) #export to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Track Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tracks(track_data,passed_dict):\n",
    "    \"\"\"\n",
    "    This is a helper function for the add_all_tracks function. It takes in a request loaded with json\n",
    "    and appends it to a dictionary passed in. There is no output. This is very similar to the add_albums \n",
    "    helper function.\n",
    "    \n",
    "    parameters\n",
    "    --------\n",
    "    track_data: json loaded request with track data using the spotify api\n",
    "    passed_dict: the dictionary this information is being appended to\n",
    "    \"\"\"\n",
    "    for i in range(len(track_data['items'])):\n",
    "        track_id = track_data['items'][i]['id']\n",
    "        passed_dict['track_id'].append(track_id)\n",
    "        track_name = track_data['items'][i]['name']\n",
    "        passed_dict['name'].append(track_name)\n",
    "        duration_ms = track_data['items'][i]['duration_ms']\n",
    "        passed_dict['duration_ms'].append(duration_ms)\n",
    "        explicit = track_data['items'][i]['explicit']\n",
    "        passed_dict['explicit'].append(explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_tracks (album_id):\n",
    "    \"\"\"\n",
    "    This function takes in an album id and returns all of its tracks. Additionally, because only 50 items are returned\n",
    "    by default, this funtion has a while loop to get all tracks in an album. \n",
    "    \"\"\"\n",
    "    album_tracks_spotify_url = \"https://api.spotify.com/v1/albums/{}/tracks\".format(album_id)\n",
    "    api_token = token #must get token from spotify to access data\n",
    "    headers = {\"Authorization\" : \"Bearer %s\"%api_token, \"Content-Type\": \"application/json\"} \n",
    "    offset = 0\n",
    "    params = {\"limit\": \"50\", \"offset\":str(offset)}\n",
    "    request = requests.get(album_tracks_spotify_url, headers=headers, params = params)\n",
    "    loaded_data_og = json.loads(request.text) #get raw data in json format\n",
    "    track_dict = {\n",
    "        \"track_id\": [],\n",
    "        \"name\": [],\n",
    "        \"duration_ms\": [],\n",
    "        \"explicit\": []  \n",
    "    }\n",
    "    add_tracks(loaded_data_og, track_dict) # propogate the dict with the first 50 entries, have to do this to access \"total\" which is the number of songs returned\n",
    "    #If an artist has more than 50 tracks in an album, get them\n",
    "    while len(track_dict[\"track_id\"]) < loaded_data_og['total']:\n",
    "        offset +=50\n",
    "        params[\"offset\"] = str(offset)\n",
    "        request = requests.get(album_tracks_spotify_url, headers=headers, params=params)\n",
    "        loaded_data = json.loads(request.text)\n",
    "        add_tracks(loaded_data, track_dict)\n",
    "    output = pd.DataFrame(track_dict) #add tracks to a dataframe\n",
    "    output[\"album_id\"] = album_id #assign album_ids for each track as a foreign key\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_track_table(album_ids):\n",
    "    \"\"\"\n",
    "    This function simply takes the add_all tracks function and makes sure requests are spread out properly. It does\n",
    "    so by making a maximum of 400 requests and then waiting 100 seconds to make another one. \n",
    "    \n",
    "    \"\"\"\n",
    "    track_df = pd.DataFrame()\n",
    "    counter = len(album_ids)# make counter length of id list\n",
    "    increment = 400 #increment number of requests by this\n",
    "    lower = 0 #set the lower bound to 0\n",
    "    upper = increment\n",
    "    while counter > 0:\n",
    "        for x in album_ids[lower:upper]:\n",
    "            track1_df = add_all_tracks(x)\n",
    "            track_df = track_df.append(track1_df)\n",
    "        lower += increment #add the increment to the lower bound\n",
    "        counter -=increment # decrement the counter\n",
    "        upper = lower + min(increment, counter)#set upper to either the increment or the counter value if it's less than the increment to prevent index out of range\n",
    "        time.sleep(100)\n",
    "    return track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_ids = [x for x in album_df['album_id']] # get all album ids in the album table\n",
    "track_df = make_track_table(album_ids)# propogate the track table with tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks_popularity(track_ids,df):\n",
    "    \"\"\"\n",
    "    Accepts a list of track_ids and a dataframe and then adds the popularity to those tracks. \n",
    "    Max number of tracks it can take is 50 tracks. This must be used because the \"get an album's tracks\"\n",
    "    endpoint used in the add_all_tracks function only returns a limited track object, meaning popularity\n",
    "    is excluded.\n",
    "    \n",
    "    \"\"\"\n",
    "    track_ids_urls = \",\".join(track_ids)\n",
    "    track_spotify_url = \"https://api.spotify.com/v1/tracks?ids={}\".format(track_ids_urls)\n",
    "    api_token = token #must get token from spotify to access data\n",
    "    headers = {\"Authorization\" : \"Bearer %s\"%api_token, \"Content-Type\": \"application/json\"} \n",
    "    request = requests.get(track_spotify_url, headers=headers)\n",
    "    loaded_test_data = json.loads(request.text) #get raw data in json format\n",
    "    for num, track_id in enumerate(track_ids):\n",
    "        df.loc[df.track_id == track_id, 'popularity'] = loaded_test_data['tracks'][num]['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_popularity_to_track(df,outer_lower, outer_upper):\n",
    "    \"\"\"\n",
    "    takes the get_tracks_popularity function above and ensures that requests are properly created.\n",
    "    Because only 50 albums can be passed in at once, the function breaks down a list of album_ids passed\n",
    "    through into groups of 50 and runs them until the upper bound is reached.\n",
    "    \n",
    "    parameters\n",
    "    ------\n",
    "    df-dataframe to be iterated through, assumes dataframe has a \"track_id\" column with track id's\n",
    "    outer_lower-lower bound of the dataframe index this function should iterate through is\n",
    "    outer_upper-upper bound of the dataframe index this function should iterate through\n",
    "    \"\"\"\n",
    "    inner_counter = outer_upper# make counter length of id list\n",
    "    inner_increment = 50 #increment number of requests by this\n",
    "    inner_lower = outer_lower #set the lower bound to 0\n",
    "    inner_upper = inner_increment\n",
    "    while inner_counter > outer_lower:\n",
    "        current_tracks = [x for x in df[\"track_id\"][inner_lower:inner_upper]]\n",
    "        get_tracks_popularity(current_tracks,df)\n",
    "        inner_lower += inner_increment #add the increment to the lower bound\n",
    "        inner_counter -=inner_increment # decrement the counter\n",
    "        inner_upper = inner_lower + min(inner_increment, inner_counter)#set upper to either the increment or the counter value if it's less than the increment to prevent index out of range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_track_table_popularity(df):\n",
    "    \"\"\"\n",
    "    takes a dataframe and applies the add_popularity_to_track function above and properly \n",
    "    spaces out requests, making 500 requests and then resting 100 seconds. \n",
    "    \n",
    "    parametrs\n",
    "    ----------\n",
    "    df-dataframe to be iterated through (assumes track_id is field)\n",
    "    \n",
    "    \"\"\"\n",
    "    outer_counter = len(df['track_id'])\n",
    "    outer_increment = 500\n",
    "    outer_lower = 0\n",
    "    outer_upper = outer_increment\n",
    "    while outer_counter > 0:\n",
    "        add_popularity_to_track(df,outer_lower,outer_upper)\n",
    "        outer_lower += outer_increment #add the increment to the lower bound\n",
    "        outer_counter -= outer_increment # decrement the counter\n",
    "        outer_upper = outer_lower + min(outer_increment, outer_counter)\n",
    "        time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_track_table_popularity(track_df)#get popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks_audio_features(track_ids,df):\n",
    "    \"\"\"\n",
    "    Accepts a list of track_ids and a dataframe and then adds the audio features to those tracks. \n",
    "    audio features added are tempo, energy, acousticness and danceability.\n",
    "    \n",
    "    parametrs\n",
    "    ----------\n",
    "    track_ids-a list of tracks to get audio features for\n",
    "    df-dataframe to append these features to (assumes track_id is a field)\n",
    "    \"\"\"\n",
    "    track_ids_urls = \",\".join(track_ids) #reformat to be accepted by the url\n",
    "    track_audio_features_spotify_url = \"https://api.spotify.com/v1/audio-features?ids={}\".format(track_ids_urls)\n",
    "    api_token = token #must get token from spotify to access data\n",
    "    headers = {\"Authorization\" : \"Bearer %s\"%api_token, \"Content-Type\": \"application/json\"} \n",
    "    request = requests.get(track_audio_features_spotify_url, headers=headers)\n",
    "    loaded_test_data = json.loads(request.text) #get raw data in json format\n",
    "    for num, track_id in enumerate(track_ids):\n",
    "        df.loc[df.track_id == track_id, 'tempo'] = loaded_test_data['audio_features'][num]['tempo']\n",
    "        df.loc[df.track_id == track_id, 'energy'] = loaded_test_data['audio_features'][num]['energy']\n",
    "        df.loc[df.track_id == track_id, 'acousticness'] = loaded_test_data['audio_features'][num]['acousticness']\n",
    "        df.loc[df.track_id == track_id, 'danceability'] = loaded_test_data['audio_features'][num]['danceability']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_audio_features_to_track(df,outer_lower, outer_upper):\n",
    "    \"\"\"\n",
    "    takes the get_tracks_audio_features function above and ensures that requests are properly created.\n",
    "    Because only 50 albums can be passed in at once, the function breaks down a list of album_ids passed\n",
    "    through into groups of 50 and runs them until the upper bound is reached.\n",
    "    \n",
    "    parameters\n",
    "    ------\n",
    "    df-dataframe to be iterated through, assumes dataframe has a \"track_id\" column with track id's\n",
    "    outer_lower-lower bound of the dataframe index this function should iterate through is\n",
    "    outer_upper-upper bound of the dataframe index this function should iterate through\"\"\"\n",
    "    \n",
    "    inner_counter = outer_upper# make counter length of id list\n",
    "    inner_increment = 50 #increment number of requests by this\n",
    "    inner_lower = outer_lower #set the lower bound to 0\n",
    "    inner_upper = inner_increment\n",
    "    while inner_counter > outer_lower:\n",
    "        current_tracks = [x for x in df[\"track_id\"][inner_lower:inner_upper]]\n",
    "        get_tracks_audio_features(current_tracks,df)\n",
    "        inner_lower += inner_increment #add the increment to the lower bound\n",
    "        inner_counter -=inner_increment # decrement the counter\n",
    "        inner_upper = inner_lower + min(inner_increment, inner_counter)#set upper to either the increment or the counter value if it's less than the increment to prevent index out of range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_track_table_audio_features(df):\n",
    "    \"\"\"\n",
    "    takes a dataframe and applies the get_tracks_audio_features function above and properly \n",
    "    spaces out requests, making 500 requests and then resting 100 seconds. \n",
    "    \n",
    "    parametrs\n",
    "    ----------\n",
    "    df-dataframe to be iterated through (assumes track_id is field)\n",
    "    \n",
    "    \"\"\"\n",
    "    outer_counter = len(df['track_id'])\n",
    "    outer_increment = 500\n",
    "    outer_lower = 0\n",
    "    outer_upper = outer_increment\n",
    "    while outer_counter > 0:\n",
    "        add_audio_features_to_track(outer_lower,outer_upper)\n",
    "        outer_lower += outer_increment #add the increment to the lower bound\n",
    "        outer_counter -= outer_increment # decrement the counter\n",
    "        outer_upper = outer_lower + min(outer_increment, outer_counter)\n",
    "        time.sleep(100)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_track_table_audio_features()#get audi0 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.to_csv(\"track.csv\", index=False)#export to cev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter credentials to upload to a mysql database \n",
    "engine = create_engine(\"mysql://USERNAME:PASSWORD@HOST/DATABASE?charset=utf8\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add each df to a table in your datbase\n",
    "track_df.to_sql('track', engine, if_exists = 'replace', index=False) \n",
    "album_df.to_sql('album', engine, if_exists = 'replace', index=False)\n",
    "artist_df.to_sql('artist', engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Functions\n",
    "Because more than one artist can appear when an artist is searched and\n",
    "the search results aren't necessarily ranked, I have decided to find the search result with the\n",
    "most amount of followers and return that artist as the \"true artist\" when determining ID's. This\n",
    "assumes that the \"true artist\" will be the one with the most followers as it is the best metric\n",
    "available. If this were a real music festival, we would have thse ID's on hand to be 100% sure\n",
    "we are referencing the right artist. However, this lets me use spotify's search endpoint and save\n",
    "some time in the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
